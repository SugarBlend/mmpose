import cv2
from collections import defaultdict
import click
import datetime
from deploy2serve.deployment.projects.sapiens.utils.palettes import COCO_WHOLEBODY_KPTS_COLORS, \
    COCO_WHOLEBODY_SKELETON_INFO
from deploy2serve.deployment.projects.sapiens.utils.adapters import visualizer_adapter
import numpy as np
from pathlib import Path
from pycocotools.coco import COCO
from mmpose.visualization.fast_visualizer import FastVisualizer
from mmengine.config import Config
import json
from tqdm import tqdm, trange
from typing import Tuple, List, Dict
import traceback

from project.annotations.pose.sapiens import Sapiens


BODY_INDICES = slice(0, 17)
FOOT_INDICES = slice(17, 23)
FACE_INDICES = slice(23, 91)
LEFT_HAND_INDICES = slice(91, 112)
RIGHT_HAND_INDICES = slice(112, 133)


COCO_STRUCT = {
    "info": {
        "year": datetime.datetime.now().year,
        "version": "1.0",
        "description": "COCO-WholeBody annotations generated by Sapiens model",
        "contributor": "Sapiens Pose Estimation",
        "url": "",
        "date_created": datetime.datetime.now().isoformat()
    },
    "images": [],
    "annotations": [],
    "categories": [
        {
            "id": 1,
            "name": "person",
            "supercategory": "person",
            "keypoints": [
                "nose", "left_eye", "right_eye", "left_ear", "right_ear", "left_shoulder", "right_shoulder",
                "left_elbow", "right_elbow", "left_wrist", "right_wrist", "left_hip", "right_hip", "left_knee",
                "right_knee", "left_ankle", "right_ankle"
            ],
            "skeleton": [
                [16, 14], [14, 12], [17, 15], [15, 13], [12, 13], [6, 12], [7, 13], [6, 7], [6, 8], [7, 9],
                [8, 10], [9, 11], [2, 3], [1, 2], [1, 3], [2, 4], [3, 5], [4, 6], [5, 7]
            ]
        }
    ],
    "licenses": [
        {
            "id": 1,
            "name": "Unknown",
            "url": ""
        }
    ]
}


def collect_annotations(
    annotations_json: str
) -> Tuple[List[List[List[float]]], Dict[int, Dict]]:
    anns_by_img = defaultdict(list)
    coco = COCO(annotations_json)
    category_ids = coco.getCatIds(catNms=["person"])
    image_ids = coco.getImgIds(catIds=category_ids)

    images_info = {img["id"]: img for img in coco.loadImgs(image_ids)}
    all_ann_ids = coco.getAnnIds(imgIds=image_ids, catIds=category_ids)

    for ann in coco.loadAnns(all_ann_ids):
        anns_by_img[ann["image_id"]].append(ann)

    detections: List[List[List[float]]] = []

    for img_id in tqdm(image_ids, desc="Fetch labels"):
        anns = anns_by_img.get(img_id)
        if not anns:
            continue

        bboxes: List[List[float]] = []
        for ann in anns:
            x1, y1, w, h = ann["bbox"]
            bboxes.append([x1, y1, x1 + w, y1 + h])

        detections.append(bboxes)

    return detections, images_info


def extract_body_parts(joints: np.ndarray, scores: np.ndarray) -> Config:
    # COCO-WholeBody: 133 joints
    # Body: 0-17 (17 joints), Feet: 17-23 (6), Face: 23-91 (68), Left Hand: 91-112 (21), Right Hand: 112-133 (21)
    return Config({
        "body": (joints[BODY_INDICES], scores[BODY_INDICES]),
        "face": (joints[FACE_INDICES], scores[FACE_INDICES]),
        "lefthand": (joints[LEFT_HAND_INDICES], scores[LEFT_HAND_INDICES]),
        "righthand": (joints[RIGHT_HAND_INDICES], scores[RIGHT_HAND_INDICES]),
        "foot": (joints[FOOT_INDICES], scores[FOOT_INDICES])
    })


def bbox_from_joints(joints: np.ndarray, scores: np.ndarray, threshold: float = 0.1) -> List[float]:
    mask = scores > threshold
    if not np.any(mask):
        return [0.0, 0.0, 0.0, 0.0]

    valid_points = joints[mask]
    x_min, y_min = np.min(valid_points, axis=0)
    x_max, y_max = np.max(valid_points, axis=0)

    return [x_min, y_min, x_max - x_min, y_max - y_min]


def joints_to_coco_format(joints: np.ndarray, scores: np.ndarray) -> List[float]:
    visibilities = np.select([scores > 0.3, scores > 0.1], [2, 1], default=0).astype(float)
    result = np.column_stack([joints, visibilities]).flatten()
    return result.tolist()


def calculate_scores(body_parts: Config, threshold: float = 0.1) -> Tuple[Dict[str, float], Dict[str, bool]]:
    scores = {}
    valid_flags = {}

    for part_name in ["body", "face", "lefthand", "righthand", "foot"]:
        part_scores = getattr(body_parts, part_name)[1]
        mean_score = float(np.mean(part_scores))
        valid_flags[part_name] = mean_score > threshold
        scores[part_name] = mean_score if valid_flags[part_name] else 0.0

    valid_scores = [score for score in scores.values() if score > 0]
    scores["wholebody"] = float(np.mean(valid_scores)) if valid_scores else 0.0

    return scores, valid_flags


def draw_boxes_on_image(image: np.ndarray, boxes: List[List[float]], expansion: float = 0.2) -> None:
    height, width = image.shape[:2]

    for box in boxes:
        if box[2] <= 0 or box[3] <= 0:
            continue

        x, y, w, h = box
        x1 = max(0, int(x - expansion * w))
        y1 = max(0, int(y - expansion * h))
        x2 = min(width, int(x + w * (1 + expansion)))
        y2 = min(height, int(y + h * (1 + expansion)))

        cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)


@click.command()
@click.option("--checkpoints-path", type=str,
              default="E:/Projects/ExecutionSamples/checkpoints/sapiens/tensorrt/model.plan", help="")
@click.option("--images-folder", type=str, default="../../dataset/images", help="")
@click.option("--detection-annotations", type=str, default="../detection/coco_annotations.json", help="")
@click.option("--output-json", type=str, default="./sapiens_coco_wholebody.json",
              help="Path to the annotation file in 'json'' format.")
@click.option("--no-preview", is_flag=True, default=False, help="Disable image preview.")
@click.option("--vis-delay", type=int, default=1, help="Hold to frame display in ms.")
def annotate(
    checkpoints_path: str,
    images_folder: str,
    detection_annotations: str,
    output_json: str,
    no_preview: bool,
    vis_delay: int
) -> None:
    detections, images_info = collect_annotations(detection_annotations)
    file_to_image_id = {img_info["file_name"]: img_id for img_id, img_info in images_info.items()}

    model = Sapiens(checkpoints_path)

    for img_id, img_info in images_info.items():
        COCO_STRUCT["images"].append({
            "id": img_info["id"],
            "width": img_info["width"],
            "height": img_info["height"],
            "file_name": img_info["file_name"],
            "license": 1,
            "flickr_url": "",
            "coco_url": "",
            "date_captured": img_info.get("date_captured", datetime.datetime.now().isoformat())
        })

    annotation_id = 1

    if not no_preview:
        meta_info = visualizer_adapter(COCO_WHOLEBODY_SKELETON_INFO, COCO_WHOLEBODY_KPTS_COLORS)
        visualizer = FastVisualizer(meta_info, radius=3, line_width=1, kpt_thr=0.3)
    else:
        visualizer = None

    for idx in trange(len(detections), desc="Annotation progress"):
        image_id = file_to_image_id[images_info[idx + 1]["file_name"]]

        image_path = Path(images_folder).joinpath(images_info[idx + 1]["file_name"])
        if not image_path.exists():
            click.echo(f"Failed to find image: {image_path}")
            continue

        image = cv2.imread(image_path.as_posix())
        if image is None:
            click.echo(f"Failed to load image: {image_path}")
            continue

        try:
            joints, keypoint_scores = model(image, np.array(detections[idx]))

            for i, (person_joints, person_scores) in enumerate(zip(joints, keypoint_scores)):
                x1, y1, x2, y2 = map(float, detections[idx][i])
                bbox = [x1, y1, x2 - x1, y2 - y1]

                body_parts = extract_body_parts(person_joints, person_scores)

                part_boxes = {
                    "face": bbox_from_joints(*body_parts.face),
                    "lefthand": bbox_from_joints(*body_parts.lefthand),
                    "righthand": bbox_from_joints(*body_parts.righthand)
                }
                scores_dict, valid_flags = calculate_scores(body_parts)

                annotation = {
                    "id": annotation_id,
                    "image_id": image_id,
                    "category_id": 1,
                    "keypoints": joints_to_coco_format(*body_parts.body),
                    "num_keypoints": int(np.sum(body_parts.body[1] > 0.1)),
                    "bbox": bbox,
                    "area": bbox[2] * bbox[3],
                    "iscrowd": 0,
                    "segmentation": [],
                    "face_box": part_boxes["face"],
                    "lefthand_box": part_boxes["lefthand"],
                    "righthand_box": part_boxes["righthand"],
                    "foot_kpts": joints_to_coco_format(*body_parts.foot),
                    "face_kpts": joints_to_coco_format(*body_parts.face),
                    "lefthand_kpts": joints_to_coco_format(*body_parts.lefthand),
                    "righthand_kpts": joints_to_coco_format(*body_parts.righthand),
                    "face_valid": valid_flags["face"],
                    "lefthand_valid": valid_flags["lefthand"],
                    "righthand_valid": valid_flags["righthand"],
                    "foot_valid": valid_flags["foot"]
                }

                COCO_STRUCT["annotations"].append(annotation)
                annotation_id += 1

                if not no_preview and visualizer:
                    visualizer.draw_pose(
                        image, Config({"keypoints": person_joints[None], "keypoint_scores": person_scores[None]})
                    )

                    bboxes = [*[part_boxes[part] for part in part_boxes if valid_flags[part]], bbox]
                    draw_boxes_on_image(image, bboxes)

            if not no_preview:
                cv2.imshow("Visualization", image)
                cv2.waitKey(vis_delay)

        except Exception as error:
            click.echo(f"Error processing image {image_path}: {error}")
            click.echo(traceback.format_exc())
            continue

    output_json = Path(output_json)
    output_json.parent.mkdir(parents=True, exist_ok=True)

    output_json.write_text(json.dumps(COCO_STRUCT, indent=2))
    click.echo(f"Results saved to {output_json}")
    click.echo(f"Generated {len(COCO_STRUCT['annotations'])} annotations")
    click.echo(f"Contains {len(COCO_STRUCT['images'])} images")
    click.echo(f"COCO format includes: info, images, annotations, categories, licenses")


if __name__ == "__main__":
    annotate()